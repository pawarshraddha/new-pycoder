{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns=\"Outcome\")      #declaring X and y data\n",
    "y=df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split   #splitting dataset\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC                 #importing model SVC\n",
    "model=SVC(kernel=\"rbf\",C=1)                 #declaring model\n",
    "model.fit(xtrain,ytrain)\n",
    "ypred=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model is : 0.7922077922077922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29cd524e760>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "acc=accuracy_score(ytest,ypred)            #accuracy- evaluation of classification model\n",
    "cm=confusion_matrix(ytest,ypred)            #confusion matrix\n",
    "print(\"Accuracy of model is :\",acc)\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       107\n",
      "           1       0.73      0.51      0.60        47\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.77      0.71      0.73       154\n",
      "weighted avg       0.78      0.79      0.78       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`sklearn.svm.LinearSVC` or\n",
      " |  :class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy. The parameter is\n",
      " |      ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int or RandomState instance, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : ndarray of shape (n_SV,)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_class,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_class-1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_class * (n_class-1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_class * (n_class-1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_class * (n_class-1) / 2)\n",
      " |  probB_ : ndarray of shape (n_class * (n_class-1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  class_weight_ : ndarray of shape (n_class,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  probA_\n",
      " |  \n",
      " |  probB_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  n_support_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC) #fuct,class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
